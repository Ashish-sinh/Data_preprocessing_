{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eabd9b7b",
   "metadata": {},
   "source": [
    "Data preprocessing steps : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48de5c1",
   "metadata": {},
   "source": [
    "# data cleaning :"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9a3436f3",
   "metadata": {},
   "source": [
    "1 . handling missing values in datasets : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d994cd4",
   "metadata": {},
   "source": [
    "::: 1. deleting the missing value row from the data type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54cd15a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deletion : \n",
    "#            in this process we have to delete that perticluler rows or \n",
    "#.           columns that containing the NULL values \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "x = pd.DataFrame( fetch_california_housing ().data  , columns = fetch_california_housing ().feature_names )\n",
    "\n",
    "# now drop that columns that containg tha NULL values using dropna function \n",
    "\n",
    "x.dropna( inplace = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1926af47",
   "metadata": {},
   "source": [
    "# univariate imputation : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7057539",
   "metadata": {},
   "source": [
    ":: univariate imputation means the simple imputation : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6219cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm)    21\n",
      "sepal width (cm)     13\n",
      "petal length (cm)    15\n",
      "petal width (cm)     13\n",
      "dtype: int64\n",
      "[['a' 'x']\n",
      " ['a' 'y']\n",
      " ['a' 'y']\n",
      " ['b' 'y']]\n"
     ]
    }
   ],
   "source": [
    "#   imputation : \n",
    "#             '''it means the data will implimented by the some val\n",
    "#     it may be mean mode or median and it can also be the regression \n",
    "#     predicted value for that : ''' \n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.datasets import load_iris \n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "x = pd.DataFrame( load_iris().data, columns = load_iris().feature_names) \n",
    "x.mask(np.random.rand(*x.shape)<0.09,inplace = True)\n",
    "\n",
    "# chek that x hav missing value or not : \n",
    "print(x.isnull().sum())\n",
    "\n",
    "# now if the missing values are occured then you have to implente tha \n",
    "# values according to your model \n",
    "\n",
    "from sklearn.impute import SimpleImputer \n",
    "imputer = SimpleImputer (strategy = 'mean') #in strategy part you can put :\n",
    "# mean , median , mode and regression prediction \n",
    "\n",
    "x[['sepal length (cm)','sepal width (cm)']] = imputer.fit_transform(x[['sepal length (cm)','sepal width (cm)']])\n",
    "# syntax is x[[ ]] double bracket : \n",
    "\n",
    "\n",
    "# simple imputer is also use in impute the values in 'catagorical data :'\n",
    "# ex :: \n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame([[\"a\", \"x\"],\n",
    "                   [np.nan, \"y\"],\n",
    "                   [\"a\", np.nan],\n",
    "                   [\"b\", \"y\"]], dtype=\"category\")\n",
    "\n",
    "imp = SimpleImputer(strategy=\"most_frequent\")\n",
    "print(imp.fit_transform(df))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0138e01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0s/mb0_47nd00vb9xhzh52jg6z00000gn/T/ipykernel_825/143916855.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test.loc[: ,'target'] = reg.predict( test[['a','b','c']])\n"
     ]
    }
   ],
   "source": [
    "#   predict imputation : \n",
    "#                         in this process we have to implement the NULL\n",
    "#            values by predicting the vaues using the mahine learning algos \n",
    "    \n",
    "\n",
    "     # 1 IS REGRESSION IMPUTATION  :: \n",
    "\n",
    "# make a dataframe containg null values : \n",
    "np.random.seed(42)\n",
    "x = np.random.uniform(low = 10 , high = 50 , size = ( 1000,3 )) \n",
    "y = np.random.randint(10,30,size = 1000).reshape(-1,1)\n",
    "\n",
    "new = np.concatenate(( x,y), axis = 1) \n",
    "new[np.random.randint(0,1000,size =200), np.random.randint(3,4,size =200)] = np.nan \n",
    "df = pd.DataFrame(new, columns = ['a','b','c','target'])\n",
    "\n",
    "df.isnull().sum() \n",
    "\n",
    "train = df.dropna()\n",
    "test = df[df.isnull().any(axis = 1) ] \n",
    "\n",
    "from sklearn.linear_model import LinearRegression \n",
    "reg = LinearRegression  ().fit( train[['a','b','c']] , train['target'])\n",
    "\n",
    "test.loc[: ,'target'] = reg.predict( test[['a','b','c']]) \n",
    "\n",
    "# concat the both data train and test data  :\n",
    "new = pd.concat([train,test],axis =0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ce69ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a           0\n",
      "b           0\n",
      "c           0\n",
      "target    187\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0s/mb0_47nd00vb9xhzh52jg6z00000gn/T/ipykernel_825/710340148.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test.loc[:,'target'] = reg.predict( test[['a','b','c']])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "a         0\n",
       "b         0\n",
       "c         0\n",
       "target    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "x = np.random.uniform(low=10, high=50, size=(1000,3)) \n",
    "y = np.random.randint(10,30, size=1000).reshape(-1,1)\n",
    "\n",
    "new = np.concatenate((x, y), axis=1) \n",
    "new[np.random.randint(0, 1000, size=200), np.random.randint( 3,4, size=200)] = np.nan \n",
    "df = pd.DataFrame(new, columns=['a', 'b', 'c', 'target'])\n",
    "\n",
    "print(df.isnull().sum()) \n",
    "\n",
    "train = df.dropna()\n",
    "test = df[df.isnull().any(axis=1)]\n",
    "\n",
    "from sklearn.linear_model import LinearRegression \n",
    "reg = LinearRegression().fit(train[['a', 'b', 'c']], train['target'])\n",
    "\n",
    "test.loc[:,'target'] = reg.predict( test[['a','b','c']])\n",
    "\n",
    "# so we can predict the the null target using the regression imputation \n",
    "\n",
    "# now concatenate the train and test data sets \n",
    "imputed_df = pd.concat([train,test],axis = 0) \n",
    "imputed_df.isnull().sum()\n",
    "\n",
    "\n",
    "     ##  NOW USE THE KNN SAME AS A LINEARREGRESSION() MODE :: \n",
    "     # do that when you leaern about it : \n",
    "        \n",
    "#         -\n",
    "#         -\n",
    "#         -\n",
    "#         -\n",
    "     ## RANDOM FOREST REGRESSION MODEL TO PREDICT THE NULL VALUES :: \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2181c0f4",
   "metadata": {},
   "source": [
    "# multivariate imputer : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afc5d0b",
   "metadata": {},
   "source": [
    "    itertive imputer :: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4dd3589a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm)    21\n",
      "sepal width (cm)     13\n",
      "petal length (cm)    15\n",
      "petal width (cm)     13\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_iterative.py:699: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sepal length (cm)    0\n",
       "sepal width (cm)     0\n",
       "petal length (cm)    0\n",
       "petal width (cm)     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intertive imputer is use when the data have missing values at random (MAR)\n",
    "# or valus completely missing at random ( MCAR) \n",
    "# also known as : multiple imputation by chained equation (MICE) \n",
    "\n",
    "# we use the bayesianridge coz it's provide the ability to handle collinear faetures\n",
    "#(when data set have the strong similor or coreleted attributes than it called collinea...) \n",
    "# and also provide the mesurement of uncertainity : \n",
    "\n",
    "# in some case the linear_regression () or other regressin\n",
    "# can use but in rare case when data is according to that type : \n",
    "np.random.seed(42)\n",
    "\n",
    "from sklearn.datasets import load_iris \n",
    "\n",
    "x = load_iris ()\n",
    "df  = pd.DataFrame( x.data,columns = x.feature_names ) \n",
    "\n",
    "# add null values : \n",
    "df.mask ( np.random.rand(*df.shape)<0.09,inplace = True )\n",
    "\n",
    "print(df.isnull().sum())\n",
    "from sklearn.experimental import enable_iterative_imputer \n",
    "from sklearn.impute import IterativeImputer \n",
    "\n",
    "from sklearn.linear_model import LinearRegression \n",
    "\n",
    "estimator = LinearRegression ()\n",
    "# you can use the other techniques also according to data \n",
    "# ex KNN random forest , best is basianridge ()\n",
    "imputer = IterativeImputer( estimator = estimator , random_state = 0 ) \n",
    "\n",
    "imputed_df = pd.DataFrame(imputer.fit_transform(df),columns = df.columns)\n",
    "imputed_df.isnull().sum()\n",
    "\n",
    "# # single and multiple imputation is avalilable in this : \n",
    "# single = genrate the single imputation data and fit to the df \n",
    "# multi = genrate the multiple imputation data and make the mean of it and \n",
    "#         than fill the data to df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee400e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d149572b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
